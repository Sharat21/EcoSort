# EcoSort: AI-Driven Garbage Segmentation and Classification Pipeline

**EcoSort** is a modular AI pipeline built to handle real-world waste classification using computer vision. It combines instance segmentation and multi-stage classification, including biodegradability and plastic subclassification. This system is optimized for conveyor belt environments in recycling facilities and supports extensibility for further research and deployment.

---

## ğŸ“ Project Structure

- **setup.py** â€“ Initializes required folders and configuration.
- **execute_pipeline.py** â€“ Core execution logic for segmentation and classification.
- **segmentation_eval.py** / **pipe-0eval.py** â€“ Evaluates segmented outputs.
- **classification.py** â€“ Trains and evaluates classification models.
- **subclassification.py** â€“ Further classifies outputs (e.g., plastic subtypes).
- **models/** â€“ Contains pretrained and fine-tuned models.
- **datasets/** â€“ Input images used for training/testing (after restructuring).
- **outputs/** â€“ Segmentation masks and prediction results.

---

## ğŸ› ï¸ Setup Instructions
1. **Install Requirements**

   Run the setup script to install dependencies and prepare the environment
   
2. **Download the TrashNet Dataset**

   Download the dataset from Kaggle:  
   [https://www.kaggle.com/datasets/feyzazkefe/trashnet?resource=download](https://www.kaggle.com/datasets/feyzazkefe/trashnet?resource=download)

3. **Restructure the Dataset**

   - Extract all images from the downloaded dataset.
   - Place all the images directly under a single directory named `datasets/`.
   - Ensure there are ** only Class_folder  in the `datasets/` directory.

4- **Run Pipeline_evaluation**
- Run Pipeline_evaluation.py


   ğŸ“Œ Notes
Ensure all scripts have correct path access to the datasets/ and outputs/ folders.

Segmentation outputs must exist before running classification scripts.

The modular design allows for future expansion, such as real-time edge deployment and integration with robotic systems.
